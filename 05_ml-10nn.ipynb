{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    bands = [col for col in df.columns if any(col.startswith(f\"{month}_B\") for month in \n",
    "            [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"])]\n",
    "\n",
    "    X = df[bands].values\n",
    "    \n",
    "    label_mapping = {\n",
    "        'A10': 1, 'A11': 1, 'A12': 1, 'A13': 1, 'A20': 1, 'A21': 1, 'A30': 1,\n",
    "        'A22': 2, 'F10': 2, 'F20': 2, 'F30': 2, 'F40': 2,\n",
    "        'E10': 3, 'E20': 3, 'E30': 3, 'B50': 3, 'B51': 3, 'B52': 3, 'B53': 3,\n",
    "        'B54': 3, 'B55': 3,\n",
    "        'B10': 4, 'B11': 4, 'B12': 4, 'B13': 4, 'B14': 4, 'B15': 4, 'B16': 4,\n",
    "        'B17': 4, 'B18': 4, 'B19': 4, 'B20': 4, 'B21': 4, 'B22': 4, 'B23': 4,\n",
    "        'B30': 4, 'B31': 4, 'B32': 4, 'B33': 4, 'B34': 4, 'B35': 4, 'B36': 4,\n",
    "        'B37': 4, 'B40': 4, 'B41': 4, 'B42': 4, 'B43': 4, 'B44': 4, 'B45': 4,\n",
    "        'B70': 4, 'B71': 4, 'B72': 4, 'B73': 4, 'B74': 4, 'B75': 4, 'B76': 4,\n",
    "        'B77': 4, 'B80': 4, 'B81': 4, 'B82': 4, 'B83': 4, 'B84': 4, 'BX1': 4,\n",
    "        'BX2': 4, 'C10': 5, 'C20': 6, 'C21': 6, 'C22': 6, 'C23': 6, 'C30': 6,\n",
    "        'C31': 6, 'C32': 6, 'C33': 6, 'CXX1': 6, 'CXX2': 6, 'CXX3': 6,\n",
    "        'CXX4': 6, 'CXX5': 6, 'CXX6': 6, 'CXX7': 6, 'CXX8': 6, 'CXX9': 6,\n",
    "        'CXXA': 6, 'CXXB': 6, 'CXXC': 6, 'CXXD': 6, 'CXXE': 6, 'D10': 7,\n",
    "        'D20': 7, 'G10': 8, 'G11': 8, 'G12': 8, 'G20': 8, 'G21': 8, 'G22': 8,\n",
    "        'G30': 8, 'G40': 8, 'G50': 8, 'H10': 9, 'H11': 9, 'H12': 9, 'H20': 9,\n",
    "        'H21': 9, 'H22': 9, 'H23': 9\n",
    "    }\n",
    "    y = df['Lc1'].map(label_mapping).values\n",
    "    return X, y\n",
    "\n",
    "# Load train and test data\n",
    "X_train, y_train = load_data('uk_monthly_train_10nn_norm.csv')\n",
    "X_test, y_test = load_data('uk_monthly_test_10nn_norm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load Data (Assuming X_train, X_test, y_train, y_test are available)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1],  # Kernel coefficient\n",
    "    'kernel': ['rbf', 'poly'],  # Try different kernels\n",
    "    'class_weight': ['balanced', None]  # Address class imbalance\n",
    "}\n",
    "\n",
    "# Initialize SVM and GridSearch\n",
    "svm = SVC()\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Predict using the best model\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred_svm = best_svm.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Remap label 9 to 0 (xgbclassifier requires labels to start from 0, not 1)\n",
    "y_train = np.where(y_train == 9, 0, y_train)\n",
    "y_test = np.where(y_test == 9, 0, y_test)\n",
    "\n",
    "# Define XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softmax\", num_class=9, eval_metric=\"mlogloss\", use_label_encoder=False)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200], \n",
    "    \"max_depth\": [3, 5, 7], \n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],  \n",
    "    \"subsample\": [0.8, 1.0],  \n",
    "    \"colsample_bytree\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                               scoring=\"accuracy\", cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Run Grid Search\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best Parameters:\", grid_search_xgb.best_params_)\n",
    "\n",
    "# Train best model\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# Convert predicted label 0 back to 9 for consistency\n",
    "y_pred_xgb = np.where(y_pred_xgb == 0, 9, y_pred_xgb)\n",
    "# Ensure y_test is also converted back for proper evaluation\n",
    "y_test = np.where(y_test == 0, 9, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export saved best models\n",
    "import joblib\n",
    "# RF\n",
    "joblib.dump(best_rf, \"best_rf_10nn.pkl\")\n",
    "# SVM\n",
    "joblib.dump(best_svm, \"best_svm_10nn.pkl\")\n",
    "scaler = joblib.dump(scaler, \"svm_scaler.pkl\") # save scaler for future use\n",
    "# XGB\n",
    "best_xgb.save_model(\"best_xgb_10nn.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import saved best models\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load models\n",
    "best_rf_10nn = joblib.load(\"best_rf_10nn.pkl\")\n",
    "\n",
    "#scaler = joblib.load(\"svm_scaler.pkl\") # Load the saved scaler for SVM\n",
    "best_svm_10nn = joblib.load(\"best_svm_10nn.pkl\")  # Load the saved model\n",
    "\n",
    "best_xgb_10nn = xgb.Booster()\n",
    "best_xgb_10nn.load_model(\"best_xgb_10nn.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    bands = [col for col in df.columns if any(col.startswith(f\"{month}_B\") for month in \n",
    "            [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"])]\n",
    "\n",
    "    X = df[bands].values\n",
    "    \n",
    "    label_mapping = {\n",
    "        'A10': 1, 'A11': 1, 'A12': 1, 'A13': 1, 'A20': 1, 'A21': 1, 'A30': 1,\n",
    "        'A22': 2, 'F10': 2, 'F20': 2, 'F30': 2, 'F40': 2,\n",
    "        'E10': 3, 'E20': 3, 'E30': 3, 'B50': 3, 'B51': 3, 'B52': 3, 'B53': 3,\n",
    "        'B54': 3, 'B55': 3,\n",
    "        'B10': 4, 'B11': 4, 'B12': 4, 'B13': 4, 'B14': 4, 'B15': 4, 'B16': 4,\n",
    "        'B17': 4, 'B18': 4, 'B19': 4, 'B20': 4, 'B21': 4, 'B22': 4, 'B23': 4,\n",
    "        'B30': 4, 'B31': 4, 'B32': 4, 'B33': 4, 'B34': 4, 'B35': 4, 'B36': 4,\n",
    "        'B37': 4, 'B40': 4, 'B41': 4, 'B42': 4, 'B43': 4, 'B44': 4, 'B45': 4,\n",
    "        'B70': 4, 'B71': 4, 'B72': 4, 'B73': 4, 'B74': 4, 'B75': 4, 'B76': 4,\n",
    "        'B77': 4, 'B80': 4, 'B81': 4, 'B82': 4, 'B83': 4, 'B84': 4, 'BX1': 4,\n",
    "        'BX2': 4, 'C10': 5, 'C20': 6, 'C21': 6, 'C22': 6, 'C23': 6, 'C30': 6,\n",
    "        'C31': 6, 'C32': 6, 'C33': 6, 'CXX1': 6, 'CXX2': 6, 'CXX3': 6,\n",
    "        'CXX4': 6, 'CXX5': 6, 'CXX6': 6, 'CXX7': 6, 'CXX8': 6, 'CXX9': 6,\n",
    "        'CXXA': 6, 'CXXB': 6, 'CXXC': 6, 'CXXD': 6, 'CXXE': 6, 'D10': 7,\n",
    "        'D20': 7, 'G10': 8, 'G11': 8, 'G12': 8, 'G20': 8, 'G21': 8, 'G22': 8,\n",
    "        'G30': 8, 'G40': 8, 'G50': 8, 'H10': 9, 'H11': 9, 'H12': 9, 'H20': 9,\n",
    "        'H21': 9, 'H22': 9, 'H23': 9\n",
    "    }\n",
    "    y = df['Lc1'].map(label_mapping).values\n",
    "    return X, y\n",
    "\n",
    "# Load train and test data\n",
    "X_val, y_val = load_data('uk_monthly_val_10nn_norm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Random Forest predictions\n",
    "rf_preds = best_rf.predict(X_val)\n",
    "\n",
    "# SVM predictions\n",
    "X_val_scaled = scaler.transform(X_val)  # Scale validation data\n",
    "svm_preds = best_svm.predict(X_val_scaled)\n",
    "\n",
    "# XGBoost predictions\n",
    "y_val_xgb = np.where(y_val == 9, 0, y_val) # Remap label 9 to 0\n",
    "xgb_preds = best_xgb.predict(X_val)\n",
    "\n",
    "# Convert predicted label 0 back to 9 for consistency\n",
    "xgb_preds = np.where(xgb_preds == 0, 9, xgb_preds)\n",
    "# Ensure y_val is also converted back for proper evaluation\n",
    "y_val_xgb = np.where(y_val_xgb == 0, 9, y_val_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"\\n🔍 {model_name} Evaluation:\\n\")\n",
    "    print(classification_report(y_true, y_pred, digits=3))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Evaluate all models\n",
    "evaluate_model(y_val, rf_preds, \"Random Forest\")\n",
    "evaluate_model(y_val, svm_preds, \"SVM\")\n",
    "evaluate_model(y_val_xgb, xgb_preds, \"XGBoost\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
